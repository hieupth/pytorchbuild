context:
  name: pytorch
  rev: main
  version: 2.8
  python: 3.12
  numpy: 2.2
  gcc: 13.3
  cmake: 3.31
  cuda: 12.8
  cudnn: 9.8
  archs: 8.6;9.0;10.0;12.0

package:
  name: ${{name|lower}}
  version: ${{version}}

source:
  git: https://github.com/pytorch/pytorch
  rev: ${{rev}}

build:
  number: 0
  string: nightly
  script:
    env:
      BUILD_TEST: OFF
      TMPDIR: $HOME/tmp
      CONDA_PREFIX: $PREFIX
      # Enable distributed training.
      USE_TENSORPIPE: ON
      USE_DISTRIBUTED: ON
      # Enable flash & mem-efficient attention.
      USE_FLASH_ATTENTION: ON
      USE_MEM_EFF_ATTENTION: ON
      # Use system libraries.
      USE_SYSTEM_SLEEF: ON
      USE_SYSTEM_PYBIND11: ON
      BUILD_CUSTOM_PROTOBUF: OFF
      # Enable Nvidia CUDA.
      USE_CUDA: ON
      TORCH_CUDA_ARCH_LIST: "${{archs}}"
      CUDA_PATH: $PREFIX:$PREFIX/targets/x86_64-linux:$CUDA_PATH
      CUDA_HOME: $PREFIX:$PREFIX/targets/x86_64-linux:$CUDA_HOME
      CUDA_BIN_PATH: $PREFIX:$PREFIX/targets/x86_64-linux:$CUDA_BIN_PATH
      CUDA_TOOLKIT_ROOT: $PREFIX:$PREFIX/targets/x86_64-linux:$CUDA_TOOLKIT_ROOT
      # Enable Nvidia multi-gpu communication.
      USE_SYSTEM_NCCL: ON
      NCCL_ROOT: $PREFIX:$PREFIX/targets/x86_64-linux:$NCCL_ROOT
    content: |
      > third_party/NNPACK/cmake/DownloadSix.cmake
      bash .ci/docker/common/install_magma_conda.sh "${{cuda}}"
      $PYTHON setup.py install \
        --prefix=$PREFIX

requirements:
  build:
    - gcc=${{gcc}}
    - gxx=${{gcc}}
    - make
    - ninja
    - mkl-static
    - mkl-include
  host:
    - python=${{python}}
    - setuptools
    - pip
    - six
    - curl
    - pybind11
    - cmake=${{cmake}}
    - pyyaml
    - protobuf
    - typing-extensions
    - nccl
    - eigen
    - sleef
    - onednn
    - sccache
    - numpy=${{numpy}}
    - libabseil
    - libcudss-dev
    - cusparselt-dev
    - cudnn=${{cudnn}}
    - cuda-cccl=${{cuda}}
    - cuda-nvcc=${{cuda}}
    - cuda-nvtx=${{cuda}}
    - cuda-nvrtc=${{cuda}}
    - cuda-toolkit=${{cuda}}
    - cuda-compiler=${{cuda}}
  run:
    - python=${{python}}
    - mkl
    - numpy>=2
    - pyyaml
    - typing-extensions
    - libcudss
    - libabseil
    - cusparselt
    - cudnn=${{cudnn}}
    - cuda-toolkit=${{cuda}}

tests:
  - script:
    - python -c "import torch; print(torch.cuda.is_available()); print(torch.cuda.get_device_name(0));"

about:
  homepage: https://github.com/hieupth/pytorchbuild
  license: MIT
  license_file: LICENSE
  description: "Build Pytorch from source"
  repository: https://github.com/hieupth/pytorchbuild

extra:
  maintainers:
    - "hieupth <64821726+hieupth@users.noreply.github.com>"