context:
  name: pytorch
  version: nightly
  rev: main
  python: 3.12
  gcc: 13.3
  cuda: 12.8
  cudnn: 9.8
  archs: 8.6;9.0;10.0;12.0;12.6

package:
  name: ${{name|lower}}
  version: ${{version}}

source:
  git: https://github.com/pytorch/pytorch.git
  rev: ${{rev}}

build:
  script:
    env:
      USE_CUDA: 1
      TORCH_CUDA_ARCH_LIST: "${{archs}}"
      CUDA_HOME: "$PREFIX:$PREFIX/targets/x86_64-linux"
      CUDA_TOOLKIT_ROOT_DIR: "$PREFIX:$PREFIX/targets/x86_64-linux"
    content: |
      > third_party/NNPACK/cmake/DownloadSix.cmake
      .ci/docker/common/install_magma_conda.sh ${{cuda}}
      $PYTHON setup.py develop \
      --single-version-externally-managed \
      --record=record.txt \
      --prefix="$PREFIX"

    

requirements:
  build:
    - gcc=${{gcc}}
    - gxx=${{gcc}}
    - make
    - ninja
    - mkl-static
    - mkl-include
  host:
    - python=3.12
    - setuptools
    - six
    - cmake
    - numpy
    - pyyaml
    - typing-extensions
    - nccl
    - cudnn
    - cuda-toolkit=${{cuda}}
    - cuda-compiler=${{cuda}}
    - cuda-nvcc=${{cuda}}
    - libabseil
    - libprotobuf
    - sleef
    - pybind11
    - eigen
  run:
    - python=3.12
    - mkl
    - numpy
    - pyyaml
    - libnuma
    - typing-extensions
    - cudnn=${{cudnn}}
    - cuda-toolkit=${{cuda}}
    - cuda-driver-dev=${{cuda}}

tests:
  - script:
    - python -c "
        import torch;
        print("is_available:", torch.cuda.is_available());
        print("Device name:", torch.cuda.get_device_name(0));
      "